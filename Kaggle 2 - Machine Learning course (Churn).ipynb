{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.stats.mstats            import winsorize\n",
    "from pandas                        import get_dummies\n",
    "from sklearn.linear_model          import LogisticRegression\n",
    "from sklearn.tree                  import DecisionTreeClassifier\n",
    "from sklearn.ensemble              import RandomForestClassifier\n",
    "from sklearn.ensemble              import GradientBoostingClassifier\n",
    "from sklearn.svm                   import SVC\n",
    "from sklearn.neural_network        import MLPClassifier\n",
    "from sklearn.neighbors             import KNeighborsClassifier\n",
    "from sklearn.metrics               import accuracy_score\n",
    "from sklearn.metrics               import auc\n",
    "from sklearn.metrics               import roc_auc_score\n",
    "from scipy.stats.mstats            import winsorize\n",
    "from scipy.stats                   import pearsonr\n",
    "from sklearn.linear_model          import LinearRegression\n",
    "from sklearn.neighbors             import KNeighborsRegressor\n",
    "from sklearn.ensemble              import GradientBoostingRegressor\n",
    "from pandas                        import DataFrame\n",
    "from sklearn.metrics               import mean_squared_error\n",
    "from sklearn.model_selection       import cross_validate\n",
    "from sklearn.ensemble              import RandomForestRegressor\n",
    "from sklearn.model_selection       import train_test_split\n",
    "from sklearn.linear_model          import SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn                       import linear_model\n",
    "from sklearn.ensemble              import BaggingClassifier\n",
    "from sklearn.naive_bayes           import GaussianNB\n",
    "from sklearn.ensemble              import StackingClassifier\n",
    "from sklearn.preprocessing         import KBinsDiscretizer\n",
    "from sklearn.model_selection       import GridSearchCV\n",
    "from sklearn.ensemble              import AdaBoostClassifier\n",
    "from sklearn.svm                   import SVC\n",
    "from sklearn.pipeline              import make_pipeline\n",
    "from sklearn.preprocessing         import StandardScaler\n",
    "from sklearn.calibration           import CalibratedClassifierCV\n",
    "from sklearn.svm                   import LinearSVC\n",
    "from sklearn.model_selection       import cross_val_score\n",
    "from sklearn.ensemble              import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data \n",
    "train = pd.read_csv('orange_churn_train.csv')\n",
    "test = pd.read_csv('orange_churn_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>...</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>NoEd</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>644.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76DJixu</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>I5dzv5f</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>xwyAw04</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76DJixu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id  Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  ...  \\\n",
       "0        3   NaN   NaN   NaN   NaN   NaN  1351.0   7.0   NaN   NaN  ...   \n",
       "1        4   NaN   NaN   NaN   NaN   NaN   644.0   0.0   NaN   NaN  ...   \n",
       "2        7   NaN   NaN   NaN   NaN   NaN  2583.0   0.0   NaN   NaN  ...   \n",
       "3        8   NaN   NaN   NaN   NaN   NaN  1463.0   7.0   NaN   NaN  ...   \n",
       "4        9   NaN   NaN   NaN   NaN   NaN    77.0   0.0   NaN   NaN  ...   \n",
       "\n",
       "    Var222      Var223  Var224  Var225  Var226  Var227         Var228  Var229  \\\n",
       "0  catzS2D  LM8l689qOp     NaN    ELof    7P5s    ZI9m           NoEd    mj86   \n",
       "1  76DJixu  LM8l689qOp     NaN     NaN    7P5s    RAYp  F2FyR07IdsN7I     NaN   \n",
       "2  I5dzv5f  LM8l689qOp     NaN     NaN    FSa2    RAYp  F2FyR07IdsN7I     NaN   \n",
       "3  xwyAw04  LM8l689qOp     NaN    kG3k    fKCe    RAYp  F2FyR07IdsN7I    mj86   \n",
       "4  76DJixu         NaN     NaN     NaN    7P5s    RAYp  F2FyR07IdsN7I     NaN   \n",
       "\n",
       "   Var230  churn  \n",
       "0     NaN      0  \n",
       "1     NaN      0  \n",
       "2     NaN      1  \n",
       "3     NaN      0  \n",
       "4     NaN      0  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col = 230\n",
      "NaN= 1604602\n"
     ]
    }
   ],
   "source": [
    "# Recap before cleaning\n",
    "print( \"col =\", len(train.iloc[:, 1:-1].columns))\n",
    "print(\"NaN=\", train.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Drop column with only NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col = 214\n",
      "NaN= 1424602\n"
     ]
    }
   ],
   "source": [
    "# Number of columns with only NaN\n",
    "train.isna().sum().to_list().count(10000)\n",
    "# Delete the columns which have only na\n",
    "train = train.dropna(axis=1, how='all')\n",
    "\n",
    "print(\"Col =\", len(train.columns))\n",
    "print(\"NaN=\", train.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Flag on NaN numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1_nan</th>\n",
       "      <th>Var2_nan</th>\n",
       "      <th>Var3_nan</th>\n",
       "      <th>Var4_nan</th>\n",
       "      <th>Var5_nan</th>\n",
       "      <th>Var6_nan</th>\n",
       "      <th>Var7_nan</th>\n",
       "      <th>Var9_nan</th>\n",
       "      <th>Var10_nan</th>\n",
       "      <th>Var11_nan</th>\n",
       "      <th>...</th>\n",
       "      <th>Var180_nan</th>\n",
       "      <th>Var181_nan</th>\n",
       "      <th>Var182_nan</th>\n",
       "      <th>Var183_nan</th>\n",
       "      <th>Var184_nan</th>\n",
       "      <th>Var186_nan</th>\n",
       "      <th>Var187_nan</th>\n",
       "      <th>Var188_nan</th>\n",
       "      <th>Var189_nan</th>\n",
       "      <th>Var190_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1_nan  Var2_nan  Var3_nan  Var4_nan  Var5_nan  Var6_nan  Var7_nan  \\\n",
       "0         1         1         1         1         1         0         0   \n",
       "1         1         1         1         1         1         0         0   \n",
       "2         1         1         1         1         1         0         0   \n",
       "3         1         1         1         1         1         0         0   \n",
       "4         1         1         1         1         1         0         0   \n",
       "\n",
       "   Var9_nan  Var10_nan  Var11_nan  ...  Var180_nan  Var181_nan  Var182_nan  \\\n",
       "0         1          1          1  ...           1           0           1   \n",
       "1         1          1          1  ...           1           0           1   \n",
       "2         1          1          1  ...           1           0           1   \n",
       "3         1          1          1  ...           1           0           1   \n",
       "4         1          1          1  ...           1           0           1   \n",
       "\n",
       "   Var183_nan  Var184_nan  Var186_nan  Var187_nan  Var188_nan  Var189_nan  \\\n",
       "0           1           1           1           1           1           1   \n",
       "1           1           1           1           1           1           1   \n",
       "2           1           1           1           1           1           0   \n",
       "3           1           1           1           1           1           1   \n",
       "4           1           1           1           1           1           1   \n",
       "\n",
       "   Var190_nan  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a NaN dummy columns for each numerical column (as a NaN Flag)\n",
    "numeric_nan_flag = pd.get_dummies(train._get_numeric_data().iloc[:, 1:-1].astype(str).replace('nan', np.nan), dummy_na=True).filter(regex='nan')\n",
    "numeric_nan_flag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Numerical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Thresh 0.7 + fillna(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# On the columns with less than 0.7 NaN, fillna with the mean \n",
    "numeric_train = train._get_numeric_data().dropna(thresh=0.7*len(train), axis=1).iloc[:, 1:-1]\n",
    "\n",
    "for i in numeric_train.columns:\n",
    "    numeric_train[i] = numeric_train[i].fillna(numeric_train[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA =  0\n",
      "Col = 39\n"
     ]
    }
   ],
   "source": [
    "# Selection of only 39 columns (cut 0.7)\n",
    "print(\"NA = \",numeric_train.isna().sum().sum())\n",
    "print(\"Col =\", len(numeric_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Bellow the thresh 0.7 -> cut + get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns droped with the thresh: 136\n"
     ]
    }
   ],
   "source": [
    "# Select all the column deleted previously with the cut 0.7 \n",
    "diff = (set(numeric_train.columns)).symmetric_difference(set(train._get_numeric_data()))\n",
    "diff = list(diff)\n",
    "diff.pop(1)\n",
    "print(\"Columns droped with the thresh:\", len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create get dummies on numerical value \n",
    "# 1. For each columns, cut number depending on the number of unique values \n",
    "# 2. With cut create categorical data \n",
    "# 3. Used the data transformed in dummies variables \n",
    "df_cut = pd.DataFrame()\n",
    "\n",
    "for i in diff:\n",
    "    if len(pd.unique(train[i])) < 5:\n",
    "        group = 4\n",
    "    elif (len(pd.unique(train[i])) > 5) & (len(pd.unique(train[i])) < 12):\n",
    "        group = 7\n",
    "    else: \n",
    "        group = 10\n",
    "    df_cut[i] = list(pd.cut(train[i], group).astype('str').replace('nan',np.nan))\n",
    "\n",
    "    \n",
    "df_cut = pd.get_dummies(df_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var104_(-0.621, 62.1]</th>\n",
       "      <th>Var104_(124.2, 186.3]</th>\n",
       "      <th>Var104_(186.3, 248.4]</th>\n",
       "      <th>Var104_(248.4, 310.5]</th>\n",
       "      <th>Var104_(310.5, 372.6]</th>\n",
       "      <th>Var104_(372.6, 434.7]</th>\n",
       "      <th>Var104_(434.7, 496.8]</th>\n",
       "      <th>Var104_(496.8, 558.9]</th>\n",
       "      <th>Var104_(558.9, 621.0]</th>\n",
       "      <th>Var104_(62.1, 124.2]</th>\n",
       "      <th>...</th>\n",
       "      <th>Var145_(2592.0, 2880.0]</th>\n",
       "      <th>Var145_(288.0, 576.0]</th>\n",
       "      <th>Var145_(576.0, 864.0]</th>\n",
       "      <th>Var23_(-0.115, 11.5]</th>\n",
       "      <th>Var23_(103.5, 115.0]</th>\n",
       "      <th>Var23_(11.5, 23.0]</th>\n",
       "      <th>Var23_(23.0, 34.5]</th>\n",
       "      <th>Var23_(34.5, 46.0]</th>\n",
       "      <th>Var23_(46.0, 57.5]</th>\n",
       "      <th>Var23_(57.5, 69.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 838 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var104_(-0.621, 62.1]  Var104_(124.2, 186.3]  Var104_(186.3, 248.4]  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   Var104_(248.4, 310.5]  Var104_(310.5, 372.6]  Var104_(372.6, 434.7]  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   Var104_(434.7, 496.8]  Var104_(496.8, 558.9]  Var104_(558.9, 621.0]  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   Var104_(62.1, 124.2]  ...  Var145_(2592.0, 2880.0]  Var145_(288.0, 576.0]  \\\n",
       "0                     0  ...                        0                      0   \n",
       "1                     0  ...                        0                      0   \n",
       "2                     0  ...                        0                      0   \n",
       "3                     0  ...                        0                      0   \n",
       "4                     0  ...                        0                      0   \n",
       "\n",
       "   Var145_(576.0, 864.0]  Var23_(-0.115, 11.5]  Var23_(103.5, 115.0]  \\\n",
       "0                      0                     0                     0   \n",
       "1                      0                     0                     0   \n",
       "2                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "4                      0                     0                     0   \n",
       "\n",
       "   Var23_(11.5, 23.0]  Var23_(23.0, 34.5]  Var23_(34.5, 46.0]  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Var23_(46.0, 57.5]  Var23_(57.5, 69.0]  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   0                   0  \n",
       "4                   0                   0  \n",
       "\n",
       "[5 rows x 838 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the cut for each columns to be reused for the testset\n",
    "cut_array = {}\n",
    "\n",
    "for i in diff:  \n",
    "    cut_array[i] = pd.cut(train[i], group, retbins=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Characterical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Keep in characterical for trees algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA =  0\n",
      "Col = 38\n"
     ]
    }
   ],
   "source": [
    "# Keep characterical values for the decision tree algo \n",
    "\n",
    "# Replace NaN with missing (but it is optional) at leat in str \n",
    "characteritic_train = train.select_dtypes(include='object').replace(np.nan, \"Missing\")\n",
    "\n",
    "print(\"NA = \",characteritic_train.isna().sum().sum())\n",
    "print(\"Col =\", len(characteritic_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Get dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA =  0\n",
      "Col = 27572\n"
     ]
    }
   ],
   "source": [
    "#With characteristic values create dummies\n",
    "characteritic_train_dummies = pd.get_dummies(characteritic_train)\n",
    "\n",
    "print(\"NA = \",characteritic_train_dummies.isna().sum().sum())\n",
    "print(\"Col =\", len(characteritic_train_dummies.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the customer_id columns\n",
    "db = pd.DataFrame(train[\"cust_id\"]).join(numeric_nan_flag)\n",
    "db = db.join(numeric_train)\n",
    "\n",
    "#DATABASE 1 - with charactere for trees models churn\n",
    "db_charactere = db.join(characteritic_train)\n",
    "db_charactere = db_charactere.join(pd.DataFrame(train[\"churn\"]))  #Add churn column\n",
    "\n",
    "# DATABASE 2 - only numeric variables for all models \n",
    "db_numeric = db.join(characteritic_train_dummies)\n",
    "db_numeric = db_numeric.join(df_cut)\n",
    "db_numeric = db_numeric.join(pd.DataFrame(train[\"churn\"])) #Add churn column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na = 0 col= 214 10000\n",
      "Na = 0 col= 253 10000\n",
      "Na = 0 col= 28625 10000\n"
     ]
    }
   ],
   "source": [
    "# Verification/Recap \n",
    "print(\"Na =\",db.isna().sum().sum(), \"col=\", len(db.columns), len(db))\n",
    "print(\"Na =\",db_charactere.isna().sum().sum(), \"col=\", len(db_charactere.columns), len(db_charactere))\n",
    "print(\"Na =\",db_numeric.isna().sum().sum(), \"col=\", len(db_numeric.columns), len(db_numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING TEST SET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na = 0 col= 28516 row: 10000\n"
     ]
    }
   ],
   "source": [
    "#1) Drop column with only NaN\n",
    "test = test.dropna(axis=1, how='all')\n",
    "# 2) Flag on NaN numeric\n",
    "test_numeric_nan_flag = pd.get_dummies(test._get_numeric_data().iloc[:, 1:-1].astype(str).replace('nan', np.nan), dummy_na=True).filter(regex='nan')\n",
    "## 3) Numerical - thresh 0.7 + fillna(mean)\n",
    "numeric_test = test._get_numeric_data().dropna(thresh=0.7*len(test), axis=1).iloc[:, 1:-1]\n",
    "\n",
    "## 3a.\n",
    "for i in numeric_test.columns:\n",
    "    numeric_test[i] = numeric_test[i].fillna(numeric_test[i].mean())\n",
    "## 4b.    \n",
    "diff_test = (set(numeric_test.columns)).symmetric_difference(set(test._get_numeric_data()))\n",
    "diff_test = list(diff_test)\n",
    "\n",
    "common_var = []\n",
    "\n",
    "for i in diff:\n",
    "    if i in diff_test:\n",
    "        common_var.append(i)\n",
    "\n",
    "df_cut_test = pd.DataFrame()\n",
    "\n",
    "for i in common_var:\n",
    "    df_cut_test[i] = list(pd.cut(test[common_var][i], cut_array[i]).astype('str').replace('nan',np.nan))\n",
    "\n",
    "    \n",
    "df_cut_test = pd.get_dummies(df_cut_test)\n",
    "    \n",
    "# 4b. Get dummies \n",
    "characteritic_test = test.select_dtypes(include='object').replace(np.nan, \"Missing\")\n",
    "characteritic_test_dummies = pd.get_dummies(characteritic_test)\n",
    "\n",
    "# Merge \n",
    "test = pd.DataFrame(test[\"cust_id\"]).join(test_numeric_nan_flag)\n",
    "test = test.join(numeric_test)\n",
    "test = test.join(df_cut_test)\n",
    "test = test.join(characteritic_test_dummies)\n",
    "\n",
    "print(\"Na =\",test.isna().sum().sum(), \"col=\", len(test.columns), \"row:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common columns in the Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On more than 27000 columns, half of them are in commun (because of the charaterical dummies mainly)\n",
    "common_col = []\n",
    "\n",
    "for i in db_numeric.columns.to_list():\n",
    "    if i in test.columns.to_list():\n",
    "        common_col.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13483"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of common columns \n",
    "len(common_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Research process but no impact on the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "#scaler = preprocessing.StandardScaler().fit(db_numeric[common_col])\n",
    "#train_common_col_standardize = scaler.transform(db_numeric[common_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = preprocessing.StandardScaler().fit(test[common_col])\n",
    "#test_common_col_standardize = scaler.transform(test[common_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_common_col_standardize = pd.DataFrame(train_common_col_standardize)\n",
    "#test_common_col_standardize = pd.DataFrame(test_common_col_standardize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Research process but no impact on the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "#pca = PCA(n_components=400)\n",
    "#train_common_col_standardize_PCA = pca.fit_transform(train_common_col_standardize)\n",
    "#test_common_col_standardize_PCA = pca.transform(test_common_col_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_common_col_standardize_PCA = pd.DataFrame(train_common_col_standardize_PCA)\n",
    "#test_common_col_standardize_PCA = pd.DataFrame(test_common_col_standardize_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Research process but no impact on the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "#pls2 = PLSRegression()\n",
    "#train_common_col_standardize_PLS = pls2.fit_transform(train_common_col_standardize)\n",
    "#test_common_col_standardize_PLS = pls2.transform(test_common_col_standardize)\n",
    "\n",
    "#train_common_col_standardize_PLS = pd.DataFrame(train_common_col_standardize_PCA)\n",
    "#test_common_col_standardize_PLS = pd.DataFrame(test_common_col_standardize_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model & Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13483\n",
      "13483\n"
     ]
    }
   ],
   "source": [
    "## ON DB_numeric  (only numeric var without characterical var)\n",
    "# Verification len matching\n",
    "print(len(db_numeric[common_col].columns))\n",
    "print(len(test[common_col].columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db_numeric[common_col].join(train[\"churn\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop Run many times the 2 following cell \n",
    "# To fine-tuning the number of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run first and then put as #comment\n",
    "data = db_numeric[common_col].join(train[\"churn\"]) \n",
    "# Run second once the personr run once \n",
    "###### data = db_numeric[common_col][selectedFeatures].join(train[\"churn\"]) \n",
    "trainingSet, testSet = train_test_split(data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet_features = trainingSet.columns[0:-1]\n",
    "testSet_features = testSet.columns[0:-1] \n",
    "\n",
    "target = 'churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 1.0 %\n",
      "Number of features: 131\n"
     ]
    }
   ],
   "source": [
    "selectedFeatures = []\n",
    "target = 'churn'\n",
    "\n",
    "p_val = 0.05\n",
    "\n",
    "trainingSet_columns = trainingSet_features\n",
    "\n",
    "for column in trainingSet_columns:\n",
    "        (pearson,pvalue) = pearsonr(trainingSet[column],trainingSet[target])\n",
    "        (f\"{column} - p-value = {pvalue} - selected : {1 if pvalue < p_val else 0}\")\n",
    "        if pvalue < p_val:\n",
    "            selectedFeatures.append(column)\n",
    "            \n",
    "print(\"Selected features:\",round(len(selectedFeatures)/len(trainingSet_features),2),\"%\")\n",
    "print(\"Number of features:\", len(selectedFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine with cross validation to see the mean score of with the new features number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "tree          = DecisionTreeClassifier()\n",
    "logistic      = LogisticRegression(solver = \"lbfgs\", max_iter = 500)\n",
    "randomForest  = RandomForestClassifier()\n",
    "boostedTree   = GradientBoostingClassifier()\n",
    "boostedTree1  = GradientBoostingClassifier()\n",
    "neuralNet     = MLPClassifier()\n",
    "neighbors     = KNeighborsClassifier()\n",
    "SGDClassifier = linear_model.SGDClassifier(loss=\"log\")\n",
    "lda           = LinearDiscriminantAnalysis()\n",
    "svc           = make_pipeline(StandardScaler(), CalibratedClassifierCV(LinearSVC()))\n",
    "gnb           = GaussianNB()\n",
    "stackClass    = StackingClassifier(estimators=[(LinearDiscriminantAnalysis())], final_estimator=GradientBoostingClassifier())\n",
    "bagging       = BaggingClassifier(base_estimator=GradientBoostingClassifier(), n_jobs=-1)\n",
    "bagging2      = BaggingClassifier(base_estimator=GradientBoostingClassifier(), n_jobs=-1)\n",
    "bagging1      = make_pipeline(StandardScaler(), BaggingClassifier(base_estimator=CalibratedClassifierCV(LinearSVC()), n_jobs=-1))\n",
    "AdaBoost      = AdaBoostClassifier()\n",
    "\n",
    "\n",
    "models = {#\"tree\"         :tree,\n",
    "          #\"logistic\"     :logistic,\n",
    "          \"randomForest\" :randomForest,\n",
    "          \"boostedTree\"  :boostedTree,\n",
    "          #\"boostedTree1\" :boostedTree1,\n",
    "          #\"svc\"          :svc,\n",
    "          #\"neuralNet\"    :neuralNet,\n",
    "          #\"neighbors\"    :neighbors,\n",
    "          #\"sgdc\"         :SGDClassifier,\n",
    "          \"lda\"          :lda,\n",
    "          #\"gnb\"          :gnb,\n",
    "          \"bagging\"       :bagging,\n",
    "          \"bagging2\"      :bagging2,\n",
    "          #\"AdaBoost\"     :AdaBoost\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForest has been trained successfully\n",
      "boostedTree has been trained successfully\n",
      "lda has been trained successfully\n",
      "bagging has been trained successfully\n",
      "bagging2 has been trained successfully\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    models[model].fit(trainingSet[selectedFeatures],trainingSet[target])\n",
    "    print(f\"{model} has been trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>randomForest</th>\n",
       "      <th>boostedTree</th>\n",
       "      <th>lda</th>\n",
       "      <th>bagging</th>\n",
       "      <th>bagging2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.924333</td>\n",
       "      <td>0.923667</td>\n",
       "      <td>0.920667</td>\n",
       "      <td>0.924667</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.670454</td>\n",
       "      <td>0.737474</td>\n",
       "      <td>0.714794</td>\n",
       "      <td>0.746038</td>\n",
       "      <td>0.737006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          randomForest  boostedTree       lda   bagging  bagging2\n",
       "Accuracy      0.924333     0.923667  0.920667  0.924667  0.925000\n",
       "AUC           0.670454     0.737474  0.714794  0.746038  0.737006"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances = {}\n",
    "\n",
    "for model in models:\n",
    "    #predictions   = models[model].predict(testSet[testSet_features])\n",
    "    #probabilities = DataFrame(models[model].predict_proba(testSet[testSet_features]))[1]\n",
    "    \n",
    "    predictions   = models[model].predict(testSet[selectedFeatures])\n",
    "    probabilities = DataFrame(models[model].predict_proba(testSet[selectedFeatures]))[1]\n",
    "    accuracy      = accuracy_score(testSet[target],predictions)\n",
    "    auc           = roc_auc_score(np.array(testSet[target]),np.array(probabilities))\n",
    "    \n",
    "    performances[model] = {\"Accuracy\":accuracy,\"AUC\":auc}\n",
    "\n",
    "pd.DataFrame(performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation - Confirm the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7386735217403484"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bagging, db_numeric[common_col][variables_132],data[target],scoring=\"roc_auc\", cv=20).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(boostedTree, db_numeric[common_col][variables_132],data[target],scoring=\"roc_auc\", cv=20).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bagging    = BaggingClassifier(base_estimator=GradientBoostingClassifier(), n_jobs=-1)\n",
    "#parameters = {'n_estimators' : [12], 'max_samples': [0.55, 0.6, 0.65, 0.7]}\n",
    "\n",
    "#GridSearch = GridSearchCV(bagging, parameters, scoring = 'roc_auc',cv=10, n_jobs=-1)\n",
    "#GridSearch.fit(data[selectedFeatures], data[target])\n",
    "#GridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best feature selection 132 variables \n",
    "\n",
    "variables_132 = ['Var126_nan', 'Var7','Var13','Var65','Var73','Var81','Var113','Var126','Var134',\n",
    "                         'Var140','Var144','Var192_1KSqrQK2Mx','Var192_AhzZptzip9','Var192_J9Vr4RQZiT',\n",
    "                         'Var192_YddrjIQ5Ph','Var192_vAsvyx7ejg','Var193_2Knk1KF','Var193_LrdZy8QqgUfkVShG',\n",
    "                         'Var193_RO12','Var195_CiJDdr4TQ0rGERIS','Var197_0Xwj','Var197_19FS','Var197_7wJ6',\n",
    "                         'Var197__8YK','Var198_3ZjbFkF','Var198_B5nJHBC','Var198_bV9grxB','Var198_fhk21Ss',\n",
    "                         'Var198_itE48fK','Var198_oWeheVi','Var198_pKHsKl9','Var199_8nstQ62E0C',\n",
    "                         'Var199_EXpWEXgaYpMJ7','Var199_IMbnnzlLVO','Var199_LH0BJkjM1L','Var199_TbQyCeZ21flwy',\n",
    "                         'Var199_ZIX6Y9cVy5','Var199_ohKlg1a','Var199_q2tfFQq','Var199_qj0HWjvF92VDZUoi',\n",
    "                         'Var199_yEFIHeU','Var200_Missing','Var202_0iyF','Var202_3taI','Var202_5hez','Var202_5xto',\n",
    "                         'Var202_6x6x','Var202_C5OU','Var202_LvoD','Var202_OFh8','Var202_Pkzj','Var202_TVqY',\n",
    "                         'Var202_VDOY','Var202_YMPo','Var202_vVrQ','Var202_xDPJ','Var203_9_Y1','Var204_TjV7',\n",
    "                         'Var204__r21','Var205_VpdQ','Var205_sJzTlal','Var206_IYzP','Var206_hAFG','Var206_haYg',\n",
    "                         'Var206_y6dw','Var206_zm5i','Var207_7M47J5GA0pTYIFxg5uy','Var207_DHn_WUyBhW_whjA88g9bvA64_',\n",
    "                         'Var207_me75fM6ugJ','Var210_g5HH','Var210_uKAI','Var212_9fipLB8rlL','Var212_CrNX',\n",
    "                         'Var212_NhsEn4L','Var212_WsRVNrF85oPU_','Var212_XfqtO3UdzaXh_','Var214_Missing',\n",
    "                         'Var216_7Ww_Xqy','Var216_7WwuNea','Var216_7WwwAA_','Var216_NGZXJ7z','Var216_NGZrD3j',\n",
    "                         'Var216_XTbPUYD','Var216__JdcICD','Var216_kq0FDQL','Var217_2Rt3','Var217_4pYq','Var217_7Rg_',\n",
    "                         'Var217_9d9v','Var217_Missing','Var217_VA4Q','Var217_Xzba','Var217__SNV','Var217_a6y6',\n",
    "                         'Var217_jtMm','Var217_rq45','Var217_x9yd','Var218_Missing','Var218_UYBR','Var218_cJvF',\n",
    "                         'Var220_3Prm94s','Var220_4UxGlow','Var220_6JW488r','Var220_8Qv6hzI','Var220__vd0Q3K',\n",
    "                         'Var220_aAJYH7D','Var220_eTk1UQz','Var221_d0EEeJi','Var221_oslk','Var221_zCkv',\n",
    "                         'Var222_2O2Rt2K','Var222_AQ0QowC','Var222_VyMCL5c','Var222_b6TozkN','Var222_catzS2D',\n",
    "                         'Var222_nDh2fT4','Var222_sd7w991','Var225_ELof','Var225_Missing','Var226_FSa2',\n",
    "                         'Var227_6fzt','Var227_RAYp','Var227_ZI9m','Var228_55YFVY9','Var228_F2FyR07IdsN7I',\n",
    "                         'Var228_NoEd','Var228_TCU50_Yjmm6GIBZ0lL_','Var228_ib5G6X1eUxUn6','Var228_iyHGyLCEkQ',\n",
    "                         'Var229_Missing','Var229_mj86']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation Output for Kaggle with the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best feature selection \n",
    "selectedFeatures = variables_132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_output = test[common_col][selectedFeatures] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selectedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var126_nan</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var65</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var126</th>\n",
       "      <th>Var134</th>\n",
       "      <th>Var140</th>\n",
       "      <th>...</th>\n",
       "      <th>Var227_ZI9m</th>\n",
       "      <th>Var228_55YFVY9</th>\n",
       "      <th>Var228_F2FyR07IdsN7I</th>\n",
       "      <th>Var228_NoEd</th>\n",
       "      <th>Var228_TCU50_Yjmm6GIBZ0lL_</th>\n",
       "      <th>Var228_ib5G6X1eUxUn6</th>\n",
       "      <th>Var228_iyHGyLCEkQ</th>\n",
       "      <th>Var229_Missing</th>\n",
       "      <th>Var229_mj86</th>\n",
       "      <th>Var147_(3.429, 4.571]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>214919.7</td>\n",
       "      <td>-10550.16</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>428230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>132</td>\n",
       "      <td>18880.8</td>\n",
       "      <td>-542628.00</td>\n",
       "      <td>-0.498959</td>\n",
       "      <td>207154.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>202726.2</td>\n",
       "      <td>-251792.00</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>691200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36</td>\n",
       "      <td>22482.0</td>\n",
       "      <td>-51358.40</td>\n",
       "      <td>-0.498959</td>\n",
       "      <td>830568.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>58</td>\n",
       "      <td>229352.1</td>\n",
       "      <td>112143.60</td>\n",
       "      <td>-0.498959</td>\n",
       "      <td>2520300.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var126_nan  Var7  Var13  Var65  Var73     Var81     Var113     Var126  \\\n",
       "0           0   0.0    0.0    9.0     18  214919.7  -10550.16  -8.000000   \n",
       "1           1   7.0   44.0    9.0    132   18880.8 -542628.00  -0.498959   \n",
       "2           0   0.0    0.0    9.0     12  202726.2 -251792.00 -12.000000   \n",
       "3           1   7.0   72.0    9.0     36   22482.0  -51358.40  -0.498959   \n",
       "4           1   7.0  160.0    9.0     58  229352.1  112143.60  -0.498959   \n",
       "\n",
       "      Var134  Var140  ...  Var227_ZI9m  Var228_55YFVY9  Var228_F2FyR07IdsN7I  \\\n",
       "0   428230.0     0.0  ...            0               0                     1   \n",
       "1   207154.0    15.0  ...            0               1                     0   \n",
       "2   691200.0     0.0  ...            0               0                     1   \n",
       "3   830568.0  1120.0  ...            0               0                     1   \n",
       "4  2520300.0    35.0  ...            0               0                     1   \n",
       "\n",
       "   Var228_NoEd  Var228_TCU50_Yjmm6GIBZ0lL_  Var228_ib5G6X1eUxUn6  \\\n",
       "0            0                           0                     0   \n",
       "1            0                           0                     0   \n",
       "2            0                           0                     0   \n",
       "3            0                           0                     0   \n",
       "4            0                           0                     0   \n",
       "\n",
       "   Var228_iyHGyLCEkQ  Var229_Missing  Var229_mj86  Var147_(3.429, 4.571]  \n",
       "0                  0               1            0                      0  \n",
       "1                  0               0            1                      0  \n",
       "2                  0               1            0                      0  \n",
       "3                  0               1            0                      0  \n",
       "4                  0               1            0                      0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict using the model based on the splitted data \n",
    "kaggle_output[\"churn\"] = bagging2.predict_proba(kaggle_output)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var126_nan</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var65</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var126</th>\n",
       "      <th>Var134</th>\n",
       "      <th>Var140</th>\n",
       "      <th>...</th>\n",
       "      <th>Var228_55YFVY9</th>\n",
       "      <th>Var228_F2FyR07IdsN7I</th>\n",
       "      <th>Var228_NoEd</th>\n",
       "      <th>Var228_TCU50_Yjmm6GIBZ0lL_</th>\n",
       "      <th>Var228_ib5G6X1eUxUn6</th>\n",
       "      <th>Var228_iyHGyLCEkQ</th>\n",
       "      <th>Var229_Missing</th>\n",
       "      <th>Var229_mj86</th>\n",
       "      <th>Var147_(3.429, 4.571]</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>214919.7</td>\n",
       "      <td>-10550.16</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>428230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>132</td>\n",
       "      <td>18880.8</td>\n",
       "      <td>-542628.00</td>\n",
       "      <td>-0.498959</td>\n",
       "      <td>207154.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>202726.2</td>\n",
       "      <td>-251792.00</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>691200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36</td>\n",
       "      <td>22482.0</td>\n",
       "      <td>-51358.40</td>\n",
       "      <td>-0.498959</td>\n",
       "      <td>830568.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>58</td>\n",
       "      <td>229352.1</td>\n",
       "      <td>112143.60</td>\n",
       "      <td>-0.498959</td>\n",
       "      <td>2520300.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var126_nan  Var7  Var13  Var65  Var73     Var81     Var113     Var126  \\\n",
       "0           0   0.0    0.0    9.0     18  214919.7  -10550.16  -8.000000   \n",
       "1           1   7.0   44.0    9.0    132   18880.8 -542628.00  -0.498959   \n",
       "2           0   0.0    0.0    9.0     12  202726.2 -251792.00 -12.000000   \n",
       "3           1   7.0   72.0    9.0     36   22482.0  -51358.40  -0.498959   \n",
       "4           1   7.0  160.0    9.0     58  229352.1  112143.60  -0.498959   \n",
       "\n",
       "      Var134  Var140  ...  Var228_55YFVY9  Var228_F2FyR07IdsN7I  Var228_NoEd  \\\n",
       "0   428230.0     0.0  ...               0                     1            0   \n",
       "1   207154.0    15.0  ...               1                     0            0   \n",
       "2   691200.0     0.0  ...               0                     1            0   \n",
       "3   830568.0  1120.0  ...               0                     1            0   \n",
       "4  2520300.0    35.0  ...               0                     1            0   \n",
       "\n",
       "   Var228_TCU50_Yjmm6GIBZ0lL_  Var228_ib5G6X1eUxUn6  Var228_iyHGyLCEkQ  \\\n",
       "0                           0                     0                  0   \n",
       "1                           0                     0                  0   \n",
       "2                           0                     0                  0   \n",
       "3                           0                     0                  0   \n",
       "4                           0                     0                  0   \n",
       "\n",
       "   Var229_Missing  Var229_mj86  Var147_(3.429, 4.571]     churn  \n",
       "0               1            0                      0  0.160888  \n",
       "1               0            1                      0  0.108164  \n",
       "2               1            0                      0  0.157571  \n",
       "3               1            0                      0  0.128318  \n",
       "4               1            0                      0  0.105571  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare the data for Kaggle format\n",
    "kaggle_output = pd.DataFrame(test[\"cust_id\"]).join(kaggle_output[\"churn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaggle_output.to_csv('output_Kaggle_Bagging_model_132_features.csv',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation Output for Kaggle with all the data (no split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var126_nan</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var65</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var126</th>\n",
       "      <th>Var134</th>\n",
       "      <th>Var140</th>\n",
       "      <th>...</th>\n",
       "      <th>Var227_ZI9m</th>\n",
       "      <th>Var228_55YFVY9</th>\n",
       "      <th>Var228_F2FyR07IdsN7I</th>\n",
       "      <th>Var228_NoEd</th>\n",
       "      <th>Var228_TCU50_Yjmm6GIBZ0lL_</th>\n",
       "      <th>Var228_ib5G6X1eUxUn6</th>\n",
       "      <th>Var228_iyHGyLCEkQ</th>\n",
       "      <th>Var229_Missing</th>\n",
       "      <th>Var229_mj86</th>\n",
       "      <th>Var147_(3.429, 4.571]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18</td>\n",
       "      <td>214919.7</td>\n",
       "      <td>-10550.16</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>428230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var126_nan  Var7  Var13  Var65  Var73     Var81    Var113  Var126  \\\n",
       "0           0   0.0    0.0    9.0     18  214919.7 -10550.16    -8.0   \n",
       "\n",
       "     Var134  Var140  ...  Var227_ZI9m  Var228_55YFVY9  Var228_F2FyR07IdsN7I  \\\n",
       "0  428230.0     0.0  ...            0               0                     1   \n",
       "\n",
       "   Var228_NoEd  Var228_TCU50_Yjmm6GIBZ0lL_  Var228_ib5G6X1eUxUn6  \\\n",
       "0            0                           0                     0   \n",
       "\n",
       "   Var228_iyHGyLCEkQ  Var229_Missing  Var229_mj86  Var147_(3.429, 4.571]  \n",
       "0                  0               1            0                      0  \n",
       "\n",
       "[1 rows x 132 columns]"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[common_col][selectedFeatures].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fit\n",
      "TestSet predicted\n",
      "CSV file created\n"
     ]
    }
   ],
   "source": [
    "#choose the best model\n",
    "model1 = baggingGS\n",
    "# Fit data \n",
    "model1.fit(db_numeric[common_col][selectedFeatures], train[\"churn\"])\n",
    "print(\"Model Fit\")\n",
    "\n",
    "#Predict\n",
    "churn_result = pd.DataFrame(test[\"cust_id\"])\n",
    "churn_result[\"churn\"] = model1.predict_proba(test[common_col][selectedFeatures])[:,1]\n",
    "print(\"TestSet predicted\")\n",
    "\n",
    "#CSV creation\n",
    "#churn_result.to_csv('kaggleEND6-ALLDATA-BAGwithGBwithGridSearch-132.csv',index=False)\n",
    "print(\"CSV file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8326969580705114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Var6',\n",
       " 'Var13',\n",
       " 'Var73',\n",
       " 'Var81',\n",
       " 'Var125',\n",
       " 'Var126',\n",
       " 'Var193_2Knk1KF',\n",
       " 'Var193_LrdZy8QqgUfkVShG',\n",
       " 'Var194_Missing',\n",
       " 'Var194_SEuy',\n",
       " 'Var195_CiJDdr4TQ0rGERIS',\n",
       " 'Var195_taul',\n",
       " 'Var198_kjvBmIU',\n",
       " 'Var199_r83_sZi',\n",
       " 'Var201_Missing',\n",
       " 'Var206_zm5i',\n",
       " 'Var207_me75fM6ugJ',\n",
       " 'Var217_RRN_',\n",
       " 'Var218_UYBR',\n",
       " 'Var218_cJvF')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(boostedTree,\n",
    "           k_features=20,\n",
    "           forward=True, \n",
    "           floating=False,\n",
    "           scoring='roc_auc',\n",
    "           cv=0)\n",
    "\n",
    "sfs1 = sfs1.fit(db_numeric[selectedFeatures], db_numeric[target])\n",
    "\n",
    "f300 = sfs1.k_feature_names_\n",
    "print(sfs1.k_score_)\n",
    "f300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFrom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from time import time\n",
    "\n",
    "threshold = np.sort(importance)[-3] + 0.01\n",
    "\n",
    "tic = time()\n",
    "sfm = SelectFromModel(lasso, threshold=threshold).fit(trainingSet[trainingSet_features],trainingSet[target])\n",
    "toc = time()\n",
    "print(\"Features selected by SelectFromModel: \")\n",
    "      f\"{feature_names[sfm.get_support()]}\")\n",
    "print(f\"Done in {toc - tic:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features selected by SelectFromModel: \"\n",
    "      f\"{feature_names[sfm.get_support()]}\")\n",
    "print(f\"Done in {toc - tic:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectBest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = SelectKBest(chi2, k=2).fit_transform(trainingSet[trainingSet_features],trainingSet[target])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
